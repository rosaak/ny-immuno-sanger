{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4737e65-a8a3-49b8-b66a-ba5b9fa94548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import dataclasses\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import statistics\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO, pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.Seq import Seq\n",
    "from IPython.display import display\n",
    "import logging\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bca4d36e-3e9d-4960-95e0-f394dbfb7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fns to check config files\n",
    "    \n",
    "\n",
    "def checking_dirs(dirname: str, log: logging, log_msg: bool=True, create_dir: bool=False):\n",
    "    dirname = str(Path(dirname).resolve())\n",
    "    res = utils.dir_exists_and_create(dirname, create_dir=create_dir)\n",
    "    if res == 4 or res == 3:\n",
    "        log.info(f\"[+] INFO: {dirname} already exists\") if log_msg else None\n",
    "        return(dirname)\n",
    "    elif res == 2:\n",
    "        log.info(f\"[X] WARNING: {dirname} doesn't exists, check the config file\") if log_msg else None\n",
    "        log.info(f\"[X] ABORT\") if log_msg else None\n",
    "        os.abort()\n",
    "    elif res == 1:\n",
    "        log.info(f\"[+] INFO: {dirname} created\") if log_msg else None\n",
    "        return(dirname)\n",
    "\n",
    "def check_files(file_path: str, log: logging):\n",
    "    file_path = str(Path(file_path).resolve())\n",
    "    if utils.file_exists(file_path) == 0:\n",
    "        log.info(f\"[X] WARNING: {file_path} doesn't exists, check the config file\")\n",
    "        log.info(f\"[X] ABORT\")\n",
    "        os.abort()\n",
    "    else:\n",
    "        log.info(f\"[+] INFO: {file_path} exists\")\n",
    "        return(file_path)\n",
    "\n",
    "def check_tsv_file(filepath: str, log: logging) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the tsv file had name and h3_nt columns and no missing values in it\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath, sep=\"\\t\")\n",
    "    if [i for i, j in zip(sorted(df.columns.tolist(), reverse=True), sorted(['name', 'h3_nt'], reverse=True)) if i == j] == ['name', 'h3_nt']:\n",
    "        log.info(f\"[+] INFO: {filepath} contains column names 'name' and 'h3_nt'\")\n",
    "        return df[['name', 'h3_nt']].dropna()\n",
    "    else:\n",
    "        log.info(f\"[+] WARNING: {filepath} should contain column names 'name' and 'h3_nt'\")\n",
    "        log.info(f\"[X] ABORT\")\n",
    "        os.abort()\n",
    "\n",
    "def create_results_excel_file_path(res_fp:str, res_fn: str):\n",
    "    return str(Path(os.path.join(res_fp, res_fn)).resolve())\n",
    "\n",
    "def get_patterns(config: configparser.ConfigParser):\n",
    "    pat_vh,pat_vl=config['Pattern']['pat_vh'], config['Pattern']['pat_vl']\n",
    "    return pat_vh, pat_vl\n",
    "\n",
    "def get_patterns_to_rm(config: configparser.ConfigParser):\n",
    "    patrm_vh, patrm_vl = config['Pattern']['vh_pat_to_rm'], config['Pattern']['vl_pat_to_rm']\n",
    "    return patrm_vh, patrm_vl\n",
    "\n",
    "def checking_ab1_files(vh_abi_dict: dict, vl_abi_dict: dict) -> str:\n",
    "    \"\"\"\n",
    "    Return sample ids\n",
    "    \"\"\"\n",
    "    vh_keys = [i for i in [*vh_abi_dict.keys()]]\n",
    "    vl_keys = [i for i in [*vl_abi_dict.keys()]]\n",
    "    if len(vh_abi_dict) == len(vl_abi_dict):\n",
    "        log.info(f\"[+] INFO: Same number of samples (n={len(vh_abi_dict)}) in vh_abi_dict and vl_abi_dict\")\n",
    "        if vh_keys == vl_keys:\n",
    "            log.info(f\"[+] INFO: The sample names in vh_abi_dict abd vl_abi_dict are same\")\n",
    "            return vl_keys\n",
    "        else:\n",
    "            log.info(f\"[+] WARNING: Some sample names in vh_abi_dict abd vl_abi_dict are different; check the patterns given in `vh_pat_to_rm` or `vl_pat_to_rm`\")\n",
    "            log.info(f\"[X] ABORT\")\n",
    "            os.abort()\n",
    "        \n",
    "def get_abi_file_path(key:str, vh_abi_dict: dict, vl_abi_dict: dict) -> str:\n",
    "    vh = vh_abi_dict.get(key)\n",
    "    vl = vl_abi_dict.get(key)\n",
    "    return vh, vl\n",
    "\n",
    "def _abi_trim(seq_record):\n",
    "    start = False   # flag for starting position of trimmed sequence\n",
    "    segment = 20    # minimum sequence length\n",
    "    trim_start = 0  # init start index\n",
    "    cutoff = 0.01   # default cutoff value for calculating base score\n",
    "    # calculate base score\n",
    "    score_list = [cutoff - (10 ** (qual / -25.0)) for qual in seq_record.letter_annotations[\"phred_quality\"]]\n",
    "    # calculate cummulative score\n",
    "    # if cummulative value < 0, set it to 0\n",
    "    # first value is set to 0, because of the assumption that\n",
    "    # the first base will always be trimmed out\n",
    "    cummul_score = [0]\n",
    "    for i in range(1, len(score_list)):\n",
    "        score = cummul_score[-1] + score_list[i]\n",
    "        if score < 0:\n",
    "            cummul_score.append(0)\n",
    "        else:\n",
    "            cummul_score.append(score)\n",
    "            if not start:\n",
    "                    # trim_start = value when cummulative score is first > 0\n",
    "                trim_start = i\n",
    "                start = True\n",
    "        # trim_finish = index of highest cummulative score,\n",
    "        # marking the end of sequence segment with highest cummulative score\n",
    "    trim_finish = cummul_score.index(max(cummul_score))\n",
    "    return seq_record[trim_start:trim_finish]\n",
    "\n",
    "def get_seqobj_from_abi(abi_fp: str) -> [Seq, Seq, list]:\n",
    "    dna = SeqIO.read(abi_fp, 'abi')\n",
    "    dna_trimmed = _abi_trim(dna)\n",
    "    quality_trimmed = dna_trimmed.letter_annotations[\"phred_quality\"]\n",
    "    return dna, dna_trimmed, quality_trimmed\n",
    "\n",
    "def get_seq_from_record(dna_obj: Seq, reverse=False) -> [Seq]:\n",
    "    if not reverse:\n",
    "        return dna_obj.seq\n",
    "    else:\n",
    "        return dna_obj.reverse_complement().seq\n",
    "\n",
    "\n",
    "def find_match_on_all_h3probes(log: logging, h3_dict: dict, d: SeqIO.SeqRecord, sample:str, vh_abi_dict: dict, vl_abi_dict: dict) -> list:\n",
    "    \"\"\"\n",
    "    returns a list of matched, h3_probe_name and h3_probe_seq, vh,vl abi file path etc. \n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for h3key, h3val in h3_dict.items():\n",
    "        seq_f = get_seq_from_record(d, reverse=False)\n",
    "        seq_r = get_seq_from_record(d, reverse=True)\n",
    "        vh_fn = vh_abi_dict.get(sample)\n",
    "        vl_fn = vl_abi_dict.get(sample)\n",
    "        if h3val in seq_f:\n",
    "            log.info(f\"[+] INFO: Forward_Strand_Match|{h3key}|{sample}|{vh_fn}|{vl_fn}\")\n",
    "            # print(f\"Forward_Strand_Match|{h3key}|{sample}|{vh_fn}|{vl_fn}|{h3val}|{seq_f}\")\n",
    "            results.append([\"Forward_Strand_Match\", h3key, sample, vh_fn, vl_fn, h3val, seq_f, d])\n",
    "        elif h3val in seq_r:\n",
    "            log.info(f\"[+] INFO: Reverse_Strand_Match|{h3key}|{sample}|{vh_fn}|{vl_fn}\")\n",
    "            # print(f\"Reverse_Strand_Match|{h3key}|{sample}|{vh_fn}|{vl_fn}|{h3val}|{seq_r}\")\n",
    "            results.append([\"Reverse_Strand_Match\", h3key, sample, vh_fn, vl_fn, h3val, seq_r, d])\n",
    "        else:\n",
    "            pass\n",
    "            # log.info(f\"[-] INFO: No_match|{h3key}|{sample}|{vh_fn}|{vl_fn}\")\n",
    "            # results.append([\"No_match\", h3key, sample, vh_fn, vl_fn, '', ''])\n",
    "    return(results)\n",
    "\n",
    "\n",
    "def copy_mtched_abi_files_to_resdir(log: logging, df_vh:pd.DataFrame, df_vl:pd.DataFrame, res_dir_vh:str, res_dir_vl:str)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    creates a dir within the results_dir for VH and VL, with h3_name\n",
    "    and copy vh and vl matched abi files into it\n",
    "    \"\"\"\n",
    "    resx = []\n",
    "    for e,i in enumerate(df_vh.h3_name.unique()[:], start=1):\n",
    "        _dfvh = df_vh[df_vh.h3_name == i]\n",
    "        _dfvl = df_vl[df_vl.h3_name == i]\n",
    "        for j in range(_dfvh.shape[0]):\n",
    "            __dfvh = _dfvh.iloc[j]\n",
    "            __dfvl = _dfvl.iloc[j]\n",
    "            # creating dirs \n",
    "            res_dir_vh_msid = checking_dirs(f\"{res_dir_vh}/{__dfvh.h3_name}\", log, log_msg=False, create_dir=True)\n",
    "            res_dir_vl_msid = checking_dirs(f\"{res_dir_vl}/{__dfvl.h3_name}\", log, log_msg=False, create_dir=True)\n",
    "            shutil.copy(__dfvh.vh_abi_fp, res_dir_vh_msid)\n",
    "            shutil.copy(__dfvl.vl_abi_fp, res_dir_vl_msid)\n",
    "            log.info(f\"[+] INFO: copying {__dfvh.vh_abi_fp} to {res_dir_vh_msid}\")\n",
    "            log.info(f\"[+] INFO: copying {__dfvh.vl_abi_fp} to {res_dir_vl_msid}\")\n",
    "            resx.append([__dfvh.h3_name, __dfvh.sample_id, f\"{res_dir_vh}/{__dfvh.sample_id}\", __dfvh.vh_abi_fp])\n",
    "            resx.append([__dfvl.h3_name, __dfvl.sample_id, f\"{res_dir_vl}/{__dfvl.sample_id}\", __dfvl.vl_abi_fp])\n",
    "    return pd.DataFrame(resx, columns=[\"h3_name\", \"sample_id\", \"abi_out_loc\", \"abi_initial_filepath\"])\n",
    "\n",
    "\n",
    "def copy_mtched_abi_files_to_resdir2(res_dir_vx:str, vx_abi_fp:str, log: logging, log_msg:bool= True, df_vh:pd.DataFrame = None, df_vl:pd.DataFrame = None)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    creates a dir within the results_dir for VH and VL, with h3_name\n",
    "    and copy vh and vl matched abi files into it\n",
    "    \"\"\"\n",
    "    def _cp_files(log: logging, df:pd.DataFrame, res_dir_vx:str, vx_abi_fp:str):\n",
    "        res = []\n",
    "        for i in df.h3_name.unique()[:]:\n",
    "            _df = df[df.h3_name == i]\n",
    "            for j in range(_df.shape[0]):\n",
    "                __df = _df.iloc[j]\n",
    "                res_dir_msid = checking_dirs(f\"{res_dir_vx}/{__df.h3_name}\", log, log_msg=False, create_dir=True)\n",
    "                shutil.copy(__df[vx_abi_fp], res_dir_msid)\n",
    "                log.info(f\"[+] INFO: copying {__df[vx_abi_fp]} to {res_dir_msid}\") if log_msg else None\n",
    "                res.append([__df.h3_name, __df.sample_id, f\"{res_dir_vx}/{__df.sample_id}\", __df[vx_abi_fp]])\n",
    "        return pd.DataFrame(res, columns=[\"h3_name\", \"sample_id\", \"abi_out_loc\", \"abi_initial_filepath\"])\n",
    "    \n",
    "    df1 = _cp_files(log, df_vh, res_dir_vh, 'vh_abi_fp')\n",
    "    df2 = _cp_files(log, df_vl, res_dir_vl, 'vl_abi_fp')\n",
    "    return pd.concat([df1,df2])\n",
    "        \n",
    "    \n",
    "    # resx, resy = [],[]\n",
    "    # for i df_vh.h3_name.unique()[:]:\n",
    "    #     _dfvh = df_vh[df_vh.h3_name == i]\n",
    "    #     for j in range(_dfvh.shape[0]):\n",
    "    #         __dfvh = _dfvh.iloc[j]\n",
    "    #         res_dir_vh_msid = checking_dirs(f\"{res_dir_vh}/{__dfvh.h3_name}\", log, log_msg=False, create_dir=True)\n",
    "    #         shutil.copy(__dfvh.vh_abi_fp, res_dir_vh_msid)\n",
    "    #         log.info(f\"[+] INFO: copying {__dfvh.vh_abi_fp} to {res_dir_vh_msid}\")\n",
    "    #         resx.append([__dfvh.h3_name, __dfvh.sample_id, f\"{res_dir_vh}/{__dfvh.sample_id}\", __dfvh.vh_abi_fp])\n",
    "    # for i in df_vl.h3_name.unique()[:]:\n",
    "    #     _dfvl = df_vl[df_vl.h3_name == i]\n",
    "    #     for j in range(_dfvl.shape[0]):\n",
    "    #         __dfvl = _dfvl.iloc[j]\n",
    "    #         res_dir_vl_msid = checking_dirs(f\"{res_dir_vl}/{__dfvl.h3_name}\", log, log_msg=False, create_dir=True)\n",
    "    #         shutil.copy(__dfvl.vl_abi_fp, res_dir_vl_msid)\n",
    "    #         log.info(f\"[+] INFO: copying {__dfvh.vl_abi_fp} to {res_dir_vl_msid}\")\n",
    "    #         resy.append([__dfvl.h3_name, __dfvl.sample_id, f\"{res_dir_vl}/{__dfvl.sample_id}\", __dfvl.vl_abi_fp])\n",
    "    # return pd.DataFrame(resx, columns=[\"h3_name\", \"sample_id\", \"abi_out_loc\", \"abi_initial_filepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d7b20-eefd-4e40-ba07-c322a7628e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c87bf2-687e-4639-bb84-728919673299",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('logs').mkdir(parents=True, exist_ok=True)\n",
    "log = utils.make_logger(\"logs/rp_log\")\n",
    "log.info(\"\\nSTART\")\n",
    "log.info(\"\\nCHECKING CONFIGURATION FILE CONTENTS...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57696b7d-c80d-4f85-b190-957326a8ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('config.ini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b6b3406-3333-4ece-a338-f29d844ad33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking config file\n",
    "# if any error occurs then program terminates; then check the config file\n",
    "\n",
    "abi_sequence_folder = checking_dirs(config['Paths']['abi_sequence_folder'], log, log_msg=True, create_dir=False)\n",
    "vh_template_sequence_folder = checking_dirs(config['Paths']['vh_template_sequence_folder'], log, log_msg=True, create_dir=False)\n",
    "vl_template_sequence_folder = checking_dirs(config['Paths']['vl_template_sequence_folder'], log, log_msg=True, create_dir=False)\n",
    "results_dir = checking_dirs(config['Paths']['results_dir'], log, log_msg=True, create_dir=True)\n",
    "h3_nt_data_sheet_filepath = check_files(config['Files']['h3_nt_data_sheet_filepath'], log)\n",
    "df = check_tsv_file(h3_nt_data_sheet_filepath, log)\n",
    "excel_path_file_name = create_results_excel_file_path(config['Paths']['results_dir'], config['Files']['output_excel_file_name'])\n",
    "\n",
    "# patters\n",
    "pat_vh, pat_vl = get_patterns(config)\n",
    "patrm_vh, patrm_vl = get_patterns_to_rm(config)\n",
    "\n",
    "# creating dirs for copying matched abi files\n",
    "res_dir_vh = checking_dirs(f\"{results_dir}/{pat_vh}\", log, log_msg=True, create_dir=True)\n",
    "res_dir_vl = checking_dirs(f\"{results_dir}/{pat_vl}\", log, log_msg=True, create_dir=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ccbf871-41f7-45e1-8f69-8c05e9867551",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"\\nCHECKING THE AB1 FILES...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f9959b-ad9a-4844-a3e8-27e29075b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_abi_dict = {i.name.replace('.abi', '').replace(patrm_vh, '') : str(i) for i in sorted([*Path(abi_sequence_folder).glob(f\"*{pat_vh}*.abi\")])}\n",
    "vl_abi_dict = {i.name.replace('.abi', '').replace(patrm_vl, '') : str(i) for i in sorted([*Path(abi_sequence_folder).glob(f\"*{pat_vl}*.abi\")])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d37fa9c-9453-4a4e-9267-355d4e13251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = checking_ab1_files(vh_abi_dict, vl_abi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0617ff0-37aa-4093-a6a6-9de63ed56466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary containing probe seq and name\n",
    "h3_dict = df.set_index('name', drop=True).to_dict().get('h3_nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64483a12-c700-4c47-a24c-3814e0fc7712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this loop  iternate through all the sample ids and find_match_on_all_h3probes function search for the probe on the normal seq and the rev complemented seq\n",
    "# if there is a match which will be returened as a list\n",
    "\n",
    "log.info(f\"\\nITERATING THROUGH EACH SAMPLE ID\")\n",
    "result_vh, result_vl = [], []\n",
    "for sample in sample_ids:\n",
    "    # print(f\">>{sample}\")\n",
    "    _vhabi, _vlabi = get_abi_file_path(key=sample, vh_abi_dict=vh_abi_dict, vl_abi_dict=vl_abi_dict)\n",
    "    vh_d, vh_dtrim, vh_dqtrimlst = get_seqobj_from_abi(_vhabi)\n",
    "    vl_d, vl_dtrim, vl_dqtrimlst = get_seqobj_from_abi(_vlabi)\n",
    "    \n",
    "    # matching each probe on  VH and VL - normal and revcomp sequence\n",
    "    vh_prob_search = find_match_on_all_h3probes(log, h3_dict, vh_d, sample, vh_abi_dict, vl_abi_dict)\n",
    "    vl_prob_search = find_match_on_all_h3probes(log, h3_dict, vl_d, sample, vh_abi_dict, vl_abi_dict)\n",
    "    if len(vh_prob_search) >=1:\n",
    "        result_vh.append(vh_prob_search)\n",
    "    if len(vl_prob_search) >=1:\n",
    "        result_vl.append(vl_prob_search)\n",
    "log.info(f\"\\nFINISH ITERATING THROUGH EACH SAMPLE ID\")\n",
    "# if vh and vl ids match then copy the files to a new place\n",
    "colnames=[\"Match\",\"h3_name\",\"sample_id\",\"vh_abi_fp\",\"vl_abi_fp\",\"probe_seq\", \"abi_seq\", \"seq_record\"]\n",
    "df_vh = pd.DataFrame(chain.from_iterable(result_vh))\n",
    "df_vl = pd.DataFrame(chain.from_iterable(result_vl))\n",
    "df_vh.columns, df_vl.columns = colnames, colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9c4be4e-9f0d-482e-8ccf-48a9913dff35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if the sahpe of df_vh and df_vl are same and the h3_name in both dataframes are same then copy the matched data to a new dir\n",
    "if(df_vl.shape == df_vh.shape) and (df_vl.h3_name == df_vh.h3_name).all():\n",
    "    log.info(f\"[+] INFO: There are {df_vl.shape[0]} matches in the dataframe between vh and vl\")\n",
    "    log.info(f\"[+] INFO: Of which {df_vh[['vh_abi_fp', 'vl_abi_fp']].drop_duplicates().shape[0]} samples has to be moved to a new dir\")\n",
    "else:\n",
    "    log.info(f\"[+] INFO: There are {df_vh.shape[0]} matches in df_vh\")\n",
    "    log.info(f\"[+] INFO: There are {df_vl.shape[0]} matches in df_vl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a8758e0-38b7-4333-ac98-58a166870c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>h3_name</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>vh_abi_fp</th>\n",
       "      <th>vl_abi_fp</th>\n",
       "      <th>probe_seq</th>\n",
       "      <th>abi_seq</th>\n",
       "      <th>seq_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forward_Strand_Match</td>\n",
       "      <td>TMH577-hF-014-G03</td>\n",
       "      <td>TMH577-hIgG1-013-A3_A03</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCAAGAGGAATTCGCCGTATTACTATGGTTCGGGGAGCTGGGGGGT...</td>\n",
       "      <td>(A, C, G, G, A, A, G, C, C, G, G, A, A, G, C, ...</td>\n",
       "      <td>(A, C, G, G, A, A, G, C, C, G, G, A, A, G, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forward_Strand_Match</td>\n",
       "      <td>TMH577-hF-012-F03</td>\n",
       "      <td>TMH577-hIgG1-013-D10</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCGAGAGGGGGCGGATACAGCTATGGCATTGACTAC</td>\n",
       "      <td>(G, G, G, C, A, T, G, C, C, T, G, G, A, G, G, ...</td>\n",
       "      <td>(G, G, G, C, A, T, G, C, C, T, G, G, A, G, G, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forward_Strand_Match</td>\n",
       "      <td>TMH577-hF-012-C01</td>\n",
       "      <td>TMH577-hIgG1-013-E11</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCGCGGGTGGGAGCCGCGGCCGATGCTTTTGATATC</td>\n",
       "      <td>(T, G, G, C, A, G, T, C, C, T, G, A, G, C, A, ...</td>\n",
       "      <td>(T, G, G, C, A, G, T, C, C, T, G, A, G, C, A, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Forward_Strand_Match</td>\n",
       "      <td>TMH577-hF-016-C12</td>\n",
       "      <td>TMH577-hIgG1-013-F3_F03</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCGAGAGGAGTGACTACGGCCGACTAC</td>\n",
       "      <td>(G, G, G, C, C, T, G, C, C, T, A, G, C, C, A, ...</td>\n",
       "      <td>(G, G, G, C, C, T, G, C, C, T, A, G, C, C, A, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forward_Strand_Match</td>\n",
       "      <td>TMH577-hF-017-C01</td>\n",
       "      <td>TMH577-hIgG1-013-G3_G03</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCGAATCTGTCTGCGTGGGAAGTACCC</td>\n",
       "      <td>(G, G, G, G, A, A, A, G, G, C, C, T, G, G, G, ...</td>\n",
       "      <td>(G, G, G, G, A, A, A, G, G, C, C, T, G, G, G, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Match            h3_name                sample_id  \\\n",
       "0  Forward_Strand_Match  TMH577-hF-014-G03  TMH577-hIgG1-013-A3_A03   \n",
       "1  Forward_Strand_Match  TMH577-hF-012-F03     TMH577-hIgG1-013-D10   \n",
       "2  Forward_Strand_Match  TMH577-hF-012-C01     TMH577-hIgG1-013-E11   \n",
       "3  Forward_Strand_Match  TMH577-hF-016-C12  TMH577-hIgG1-013-F3_F03   \n",
       "4  Forward_Strand_Match  TMH577-hF-017-C01  TMH577-hIgG1-013-G3_G03   \n",
       "\n",
       "                                           vh_abi_fp  \\\n",
       "0  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "1  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "2  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "3  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "4  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "\n",
       "                                           vl_abi_fp  \\\n",
       "0  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "1  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "2  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "3  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "4  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "\n",
       "                                           probe_seq  \\\n",
       "0  GCAAGAGGAATTCGCCGTATTACTATGGTTCGGGGAGCTGGGGGGT...   \n",
       "1               GCGAGAGGGGGCGGATACAGCTATGGCATTGACTAC   \n",
       "2               GCGCGGGTGGGAGCCGCGGCCGATGCTTTTGATATC   \n",
       "3                        GCGAGAGGAGTGACTACGGCCGACTAC   \n",
       "4                        GCGAATCTGTCTGCGTGGGAAGTACCC   \n",
       "\n",
       "                                             abi_seq  \\\n",
       "0  (A, C, G, G, A, A, G, C, C, G, G, A, A, G, C, ...   \n",
       "1  (G, G, G, C, A, T, G, C, C, T, G, G, A, G, G, ...   \n",
       "2  (T, G, G, C, A, G, T, C, C, T, G, A, G, C, A, ...   \n",
       "3  (G, G, G, C, C, T, G, C, C, T, A, G, C, C, A, ...   \n",
       "4  (G, G, G, G, A, A, A, G, G, C, C, T, G, G, G, ...   \n",
       "\n",
       "                                          seq_record  \n",
       "0  (A, C, G, G, A, A, G, C, C, G, G, A, A, G, C, ...  \n",
       "1  (G, G, G, C, A, T, G, C, C, T, G, G, A, G, G, ...  \n",
       "2  (T, G, G, C, A, G, T, C, C, T, G, A, G, C, A, ...  \n",
       "3  (G, G, G, C, C, T, G, C, C, T, A, G, C, C, A, ...  \n",
       "4  (G, G, G, G, A, A, A, G, G, C, C, T, G, G, G, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67e4a15a-2f74-4566-bcc7-d65b3dd65973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>h3_name</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>vh_abi_fp</th>\n",
       "      <th>vl_abi_fp</th>\n",
       "      <th>probe_seq</th>\n",
       "      <th>abi_seq</th>\n",
       "      <th>seq_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reverse_Strand_Match</td>\n",
       "      <td>TMH577-hF-012-E03</td>\n",
       "      <td>TMH577-hIgG1-013-A10</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCGAGACCCTTTTGGAGCGGCCTAACAAGAGAAAACTACTATTACG...</td>\n",
       "      <td>(T, C, A, C, G, G, G, G, A, T, T, T, C, C, A, ...</td>\n",
       "      <td>(A, T, G, C, C, A, A, A, G, C, C, C, A, A, G, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reverse_Strand_Match</td>\n",
       "      <td>TMH577-hF-015-C12</td>\n",
       "      <td>TMH577-hIgG1-013-A11</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCTAGGTACTACTACGGTATGGACGTC</td>\n",
       "      <td>(T, T, A, T, G, G, G, A, C, T, T, T, C, C, T, ...</td>\n",
       "      <td>(C, C, G, T, T, C, C, A, A, A, A, C, C, A, A, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reverse_Strand_Match</td>\n",
       "      <td>TMH577-hF-014-B12</td>\n",
       "      <td>TMH577-hIgG1-013-A12</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCCACACGCAACCCTCTTCCACGGCAATATTACTACTACTTCTACG...</td>\n",
       "      <td>(T, T, T, C, T, C, T, C, C, A, C, A, G, G, T, ...</td>\n",
       "      <td>(T, A, T, A, G, G, G, C, C, C, T, T, G, G, G, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reverse_Strand_Match</td>\n",
       "      <td>TMH577-hF-015-C08</td>\n",
       "      <td>TMH577-hIgG1-013-A12</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCCACACGCAACCCTCTTCCACGGCAATATTACTACTACTTCTACG...</td>\n",
       "      <td>(T, T, T, C, T, C, T, C, C, A, C, A, G, G, T, ...</td>\n",
       "      <td>(T, A, T, A, G, G, G, C, C, C, T, T, G, G, G, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reverse_Strand_Match</td>\n",
       "      <td>TMH577-hF-015-D08</td>\n",
       "      <td>TMH577-hIgG1-013-A12</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>/Users/rp/Desktop/purge/ny-immuno-sanger/data0...</td>\n",
       "      <td>GCCACACGCAACCCTCTTCCACGGCAATATTACTACTACTTCTACG...</td>\n",
       "      <td>(T, T, T, C, T, C, T, C, C, A, C, A, G, G, T, ...</td>\n",
       "      <td>(T, A, T, A, G, G, G, C, C, C, T, T, G, G, G, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Match            h3_name             sample_id  \\\n",
       "0  Reverse_Strand_Match  TMH577-hF-012-E03  TMH577-hIgG1-013-A10   \n",
       "1  Reverse_Strand_Match  TMH577-hF-015-C12  TMH577-hIgG1-013-A11   \n",
       "2  Reverse_Strand_Match  TMH577-hF-014-B12  TMH577-hIgG1-013-A12   \n",
       "3  Reverse_Strand_Match  TMH577-hF-015-C08  TMH577-hIgG1-013-A12   \n",
       "4  Reverse_Strand_Match  TMH577-hF-015-D08  TMH577-hIgG1-013-A12   \n",
       "\n",
       "                                           vh_abi_fp  \\\n",
       "0  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "1  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "2  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "3  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "4  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "\n",
       "                                           vl_abi_fp  \\\n",
       "0  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "1  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "2  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "3  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "4  /Users/rp/Desktop/purge/ny-immuno-sanger/data0...   \n",
       "\n",
       "                                           probe_seq  \\\n",
       "0  GCGAGACCCTTTTGGAGCGGCCTAACAAGAGAAAACTACTATTACG...   \n",
       "1                        GCTAGGTACTACTACGGTATGGACGTC   \n",
       "2  GCCACACGCAACCCTCTTCCACGGCAATATTACTACTACTTCTACG...   \n",
       "3  GCCACACGCAACCCTCTTCCACGGCAATATTACTACTACTTCTACG...   \n",
       "4  GCCACACGCAACCCTCTTCCACGGCAATATTACTACTACTTCTACG...   \n",
       "\n",
       "                                             abi_seq  \\\n",
       "0  (T, C, A, C, G, G, G, G, A, T, T, T, C, C, A, ...   \n",
       "1  (T, T, A, T, G, G, G, A, C, T, T, T, C, C, T, ...   \n",
       "2  (T, T, T, C, T, C, T, C, C, A, C, A, G, G, T, ...   \n",
       "3  (T, T, T, C, T, C, T, C, C, A, C, A, G, G, T, ...   \n",
       "4  (T, T, T, C, T, C, T, C, C, A, C, A, G, G, T, ...   \n",
       "\n",
       "                                          seq_record  \n",
       "0  (A, T, G, C, C, A, A, A, G, C, C, C, A, A, G, ...  \n",
       "1  (C, C, G, T, T, C, C, A, A, A, A, C, C, A, A, ...  \n",
       "2  (T, A, T, A, G, G, G, C, C, C, T, T, G, G, G, ...  \n",
       "3  (T, A, T, A, G, G, G, C, C, C, T, T, G, G, G, ...  \n",
       "4  (T, A, T, A, G, G, G, C, C, C, T, T, G, G, G, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a51072-8286-4e7d-9343-c062338097e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqRecord(seq=Seq('ACGGTCAAAGCCCCAAGGGTCAAGGCCTGGGCCTGCCCCAGAAAGCTTACTCAC...CAA'), id='40250105', name='TMH577-hIgG1-013-A5_A05_GATC-VH60-2617917.abi', description='', dbxrefs=[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vh.seq_record.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e8405bc-a5d7-4953-936e-c5fcc9d5da98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqRecord(seq=Seq('GGGCAGGCTGAGGAAGCAGGGTCTGACAGGGAGGGCAGAGGTCCTTGCTCAGGA...CTT'), id='40250607', name='TMH577-hIgG1-014-C10_VL79.abi', description='', dbxrefs=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vl.seq_record.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ecdf5c3-1e98-400d-9ccd-e674d1f74247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a158a90-ff8d-405a-8a08-ed467320b5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2c31e68-eee6-45be-b972-98e4ca89f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# need to work on this\n",
    "def copy_mtched_abi_files_to_resdir2(res_dir_vx:str, vx_abi_fp:str, log: logging, log_msg:bool= True, df_vh:pd.DataFrame = None, df_vl:pd.DataFrame = None)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    creates a dir within the results_dir for VH and VL, with h3_name\n",
    "    and copy vh and vl matched abi files into it\n",
    "    \"\"\"\n",
    "    def _cp_files(log: logging, df:pd.DataFrame, res_dir_vx:str, vx_abi_fp:str):\n",
    "        res = []\n",
    "        for i in df.h3_name.unique()[:]:\n",
    "            _df = df[df.h3_name == i]\n",
    "            for j in range(_df.shape[0]):\n",
    "                __df = _df.iloc[j]\n",
    "                res_dir_msid = checking_dirs(f\"{res_dir_vx}/{__df.h3_name}\", log, log_msg=False, create_dir=True)\n",
    "                shutil.copy(__df[vx_abi_fp], res_dir_msid)\n",
    "                log.info(f\"[+] INFO: copying {__df[vx_abi_fp]} to {res_dir_msid}\") if log_msg else None\n",
    "                res.append([__df.h3_name, __df.sample_id, f\"{res_dir_vx}/{__df.sample_id}\", __df[vx_abi_fp]])\n",
    "        return pd.DataFrame(res, columns=[\"h3_name\", \"sample_id\", \"abi_out_loc\", \"abi_initial_filepath\"])\n",
    "    \n",
    "    df1 = _cp_files(log, df_vh, res_dir_vh, 'vh_abi_fp')\n",
    "    df2 = _cp_files(log, df_vl, res_dir_vl, 'vl_abi_fp')\n",
    "    return pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605f2db-56cb-43e1-95d1-f267e5d10659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b824af9-52af-41f5-bbca-68aa7d3859f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'h3_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCOPY MATCHED ABI FILES INTO NEW LOCATION\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m res_df_copy \u001b[38;5;241m=\u001b[39m \u001b[43mcopy_mtched_abi_files_to_resdir2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_vh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_vl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_dir_vh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_dir_vl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFINISH COPYING FILES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mcopy_mtched_abi_files_to_resdir2\u001b[0;34m(res_dir_vx, vx_abi_fp, log, log_msg, df_vh, df_vl)\u001b[0m\n\u001b[1;32m    176\u001b[0m             res\u001b[38;5;241m.\u001b[39mappend([__df\u001b[38;5;241m.\u001b[39mh3_name, __df\u001b[38;5;241m.\u001b[39msample_id, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres_dir_vx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__df\u001b[38;5;241m.\u001b[39msample_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, __df[vx_abi_fp]])\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(res, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh3_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabi_out_loc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabi_initial_filepath\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 179\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43m_cp_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_vh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_dir_vh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvh_abi_fp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m df2 \u001b[38;5;241m=\u001b[39m _cp_files(log, df_vl, res_dir_vl, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvl_abi_fp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat([df1,df2])\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mcopy_mtched_abi_files_to_resdir2.<locals>._cp_files\u001b[0;34m(log, df, res_dir_vx, vx_abi_fp)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cp_files\u001b[39m(log: logging, df:pd\u001b[38;5;241m.\u001b[39mDataFrame, res_dir_vx:\u001b[38;5;28mstr\u001b[39m, vx_abi_fp:\u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    168\u001b[0m     res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh3_name\u001b[49m\u001b[38;5;241m.\u001b[39munique()[:]:\n\u001b[1;32m    170\u001b[0m         _df \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mh3_name \u001b[38;5;241m==\u001b[39m i]\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'h3_name'"
     ]
    }
   ],
   "source": [
    "log.info(f\"\\nCOPY MATCHED ABI FILES INTO NEW LOCATION\")\n",
    "res_df_copy = copy_mtched_abi_files_to_resdir2(log, log_msg=True, df_vh, df_vl, res_dir_vh, res_dir_vl)\n",
    "log.info(f\"\\nFINISH COPYING FILES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9548d76-dac0-4b69-a338-a0f537f77f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TMH577-hF-014-B12    13\n",
       "TMH577-hF-015-C08    13\n",
       "TMH577-hF-015-D08    13\n",
       "TMH577-hF-017-G04    13\n",
       "TMH577-hF-012-E03     7\n",
       "                     ..\n",
       "TMH577-hF-017-H10     1\n",
       "TMH577-hF-016-D06     1\n",
       "TMH577-hF-016-C03     1\n",
       "TMH577-hF-004-G09     1\n",
       "TMH577-hF-017-D03     1\n",
       "Name: h3_name, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_copy.h3_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac2471-522c-46b1-a88b-e722463e0e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f871ee0-0e90-41fc-a337-38e6b370dfd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Note\n",
    "- same TMH577-hF-012-E03 for eg: matches TMH577-hIgG1-014-H6_H06, TMH577-hIgG1-014-G4_G04, TMH577-hIgG1-014-A5_A05, TMH577-hIgG1-013-H7_H07, TMH577-hIgG1-013-H3_H03, TMH577-hIgG1-013-A10\n",
    "- todo\n",
    "    - create a dict for template_gp_for_vh and vl\n",
    "    - copy the abi files to a new dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3231ca65-e4b3-4319-83c3-1fb6f8b393d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for template_strand in os.listdir(vh_template_sequence_folder):\n",
    "#     parsed_template_strand = template_strand.split('VH-')[1].split('.gb')[0]\n",
    "#     print(f\"{template_strand} | {parsed_template_strand}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b51d58-5257-4cad-b6fb-de7bd42c52e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb31846a-0a14-447e-8527-2f0664e8db24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed13589-6279-401d-bbbc-fa83f326e8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyBio",
   "language": "python",
   "name": "pybio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
